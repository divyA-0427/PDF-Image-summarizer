{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bf4c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch, transformers, pytesseract, cv2, pdf2image\n",
    "\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"Transformers:\", transformers.__version__)\n",
    "print(\"Pytesseract:\", pytesseract.get_tesseract_version())\n",
    "print(\"OpenCV:\", cv2.__version__)\n",
    "print(\"pdf2image:\", pdf2image.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c43d3fa7-98be-4014-86af-38676221f054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.12.0.88-cp37-abi3-win_amd64.whl.metadata (19 kB)\n",
      "Collecting numpy<2.3.0,>=2 (from opencv-python)\n",
      "  Downloading numpy-2.2.6-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Downloading opencv_python-4.12.0.88-cp37-abi3-win_amd64.whl (39.0 MB)\n",
      "   ---------------------------------------- 0.0/39.0 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 6.8/39.0 MB 42.0 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 16.3/39.0 MB 44.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 25.7/39.0 MB 45.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 35.7/39.0 MB 46.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 39.0/39.0 MB 43.5 MB/s  0:00:00\n",
      "Downloading numpy-2.2.6-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 51.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 43.8 MB/s  0:00:00\n",
      "Installing collected packages: numpy, opencv-python\n",
      "\n",
      "  Attempting uninstall: numpy\n",
      "\n",
      "    Found existing installation: numpy 1.26.4\n",
      "\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "    Uninstalling numpy-1.26.4:\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [opencv-python]\n",
      "   -------------------- ------------------- 1/2 [opencv-python]\n",
      "   -------------------- ------------------- 1/2 [opencv-python]\n",
      "   -------------------- ------------------- 1/2 [opencv-python]\n",
      "   -------------------- ------------------- 1/2 [opencv-python]\n",
      "   -------------------- ------------------- 1/2 [opencv-python]\n",
      "   ---------------------------------------- 2/2 [opencv-python]\n",
      "\n",
      "Successfully installed numpy-2.2.6 opencv-python-4.12.0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.6 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39f177fb-d6a8-473e-98d7-cde597142d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdf2image\n",
      "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: pillow in c:\\users\\manish\\anaconda3\\lib\\site-packages (from pdf2image) (10.4.0)\n",
      "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: pdf2image\n",
      "Successfully installed pdf2image-1.17.0\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install pdf2image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f5eff0a-07c5-4f2d-aad2-5a69837737ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"   # silence symlink warning on Windows\n",
    "\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pdf2image import convert_from_path\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7d1bdcb-b6de-4acc-8359-38a982cd8629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub[hf_xet] in c:\\users\\manish\\anaconda3\\lib\\site-packages (0.34.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\manish\\anaconda3\\lib\\site-packages (from huggingface_hub[hf_xet]) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\manish\\anaconda3\\lib\\site-packages (from huggingface_hub[hf_xet]) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\manish\\anaconda3\\lib\\site-packages (from huggingface_hub[hf_xet]) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\manish\\anaconda3\\lib\\site-packages (from huggingface_hub[hf_xet]) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\manish\\anaconda3\\lib\\site-packages (from huggingface_hub[hf_xet]) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\manish\\anaconda3\\lib\\site-packages (from huggingface_hub[hf_xet]) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\manish\\anaconda3\\lib\\site-packages (from huggingface_hub[hf_xet]) (4.11.0)\n",
      "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface_hub[hf_xet])\n",
      "  Downloading hf_xet-1.1.9-cp37-abi3-win_amd64.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\manish\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub[hf_xet]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\manish\\anaconda3\\lib\\site-packages (from requests->huggingface_hub[hf_xet]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\manish\\anaconda3\\lib\\site-packages (from requests->huggingface_hub[hf_xet]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\manish\\anaconda3\\lib\\site-packages (from requests->huggingface_hub[hf_xet]) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\manish\\anaconda3\\lib\\site-packages (from requests->huggingface_hub[hf_xet]) (2025.8.3)\n",
      "Downloading hf_xet-1.1.9-cp37-abi3-win_amd64.whl (2.8 MB)\n",
      "   ---------------------------------------- 0.0/2.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.8/2.8 MB 23.3 MB/s  0:00:00\n",
      "Installing collected packages: hf-xet\n",
      "Successfully installed hf-xet-1.1.9\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install huggingface_hub[hf_xet]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "739c22b8-185c-4b24-8ddb-4668e66b940e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import logging\n",
    "logging.set_verbosity_error()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "489b2aea-c122-4d71-8495-676f5575d11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28150ab3-8e7c-4065-91a4-2b6147da20de",
   "metadata": {},
   "outputs": [],
   "source": [
    "TESSERACT_EXE = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"  # adapt if needed\n",
    "pytesseract.pytesseract.tesseract_cmd = TESSERACT_EXE\n",
    "\n",
    "CAPTION_MODEL = \"nlpconnect/vit-gpt2-image-captioning\"   # lightweight caption model\n",
    "SUMMARIZER_MODEL = \"google/flan-t5-small\"                # lightweight local summarizer (CPU OK)\n",
    "# If you prefer OpenAI for summarization, see function summarize_with_openai below.\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef864399-4c9b-4572-81b1-5039804acca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_model = VisionEncoderDecoderModel.from_pretrained(CAPTION_MODEL)\n",
    "feature_extractor = ViTImageProcessor.from_pretrained(CAPTION_MODEL)\n",
    "caption_tokenizer = AutoTokenizer.from_pretrained(CAPTION_MODEL)\n",
    "if DEVICE == \"cuda\":\n",
    "    caption_model.to(\"cuda\")\n",
    "\n",
    "# Load summarizer pipeline (local fallback)\n",
    "summarizer = pipeline(\"text2text-generation\", model=SUMMARIZER_MODEL, device=0 if DEVICE==\"cuda\" else -1)\n",
    "\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def image_from_path_or_pil(x):\n",
    "    if isinstance(x, str):\n",
    "        img = Image.open(x).convert(\"RGB\")\n",
    "    elif isinstance(x, Image.Image):\n",
    "        img = x.convert(\"RGB\")\n",
    "    else:\n",
    "        raise ValueError(\"Input must be filepath or PIL.Image\")\n",
    "    return img\n",
    "\n",
    "def pdf_to_images(pdf_path, dpi=200, poppler_path=None):\n",
    "    # poppler_path needed on Windows if poppler not in PATH\n",
    "    images = convert_from_path(pdf_path, dpi=dpi, poppler_path=poppler_path)\n",
    "    return images\n",
    "\n",
    "def preprocess_for_ocr(pil_img):\n",
    "    # basic denoise + threshold for better OCR\n",
    "    arr = np.array(pil_img.convert(\"RGB\"))\n",
    "    gray = cv2.cvtColor(arr, cv2.COLOR_RGB2GRAY)\n",
    "    # Gaussian blur then Otsu threshold\n",
    "    blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "    _, thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    return Image.fromarray(thresh)\n",
    "\n",
    "def ocr_image_get_text_and_conf(pil_img, lang=\"eng\"):\n",
    "    \"\"\"\n",
    "    Returns (text, avg_confidence_0_to_1)\n",
    "    \"\"\"\n",
    "    pre = preprocess_for_ocr(pil_img)\n",
    "    data = pytesseract.image_to_data(pre, output_type=Output.DICT, lang=lang)\n",
    "    words = []\n",
    "    confs = []\n",
    "    for i, w in enumerate(data[\"text\"]):\n",
    "        if w and w.strip():\n",
    "            words.append(w)\n",
    "            try:\n",
    "                c = float(data[\"conf\"][i])\n",
    "                if c >= 0:\n",
    "                    confs.append(c)\n",
    "            except:\n",
    "                pass\n",
    "    text = \" \".join(words).strip()\n",
    "    avg_conf = (sum(confs)/len(confs))/100.0 if confs else 0.0\n",
    "    return text, avg_conf\n",
    "\n",
    "def generate_caption(pil_img, max_length=40):\n",
    "    img_for_model = pil_img.convert(\"RGB\")\n",
    "    pixel_values = feature_extractor(images=img_for_model, return_tensors=\"pt\").pixel_values\n",
    "    if DEVICE == \"cuda\":\n",
    "        pixel_values = pixel_values.to(\"cuda\")\n",
    "    output_ids = caption_model.generate(pixel_values, max_length=max_length, num_beams=4)\n",
    "    caption = caption_tokenizer.decode(output_ids[0], skip_special_tokens=True).strip()\n",
    "    return caption\n",
    "\n",
    "def build_prompt(ocr_text, caption):\n",
    "    prompt = f\"\"\"OCR:\n",
    "{ocr_text}\n",
    "\n",
    "Caption:\n",
    "{caption}\n",
    "\n",
    "INSTRUCTION:\n",
    "Produce a concise 3-sentence professional summary.\n",
    "- Sentence1: describe the main scene (what's visible).\n",
    "- Sentence2: summarize important textual content (numbers, dates, amounts).\n",
    "- Sentence3: recommended action or caveat.\n",
    "Also append a confidence score (0-1) on its own line and list data sources used (OCR/caption).\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "def summarize_with_local_model(prompt):\n",
    "    # Uses local Flan-T5 pipeline; returns string\n",
    "    out = summarizer(prompt, max_length=200, do_sample=False)\n",
    "    if isinstance(out, list):\n",
    "        text = out[0].get(\"generated_text\") or out[0].get(\"text\") or str(out[0])\n",
    "    else:\n",
    "        text = str(out)\n",
    "    return text.strip()\n",
    "\n",
    "# Optional: better/higher-quality summarization using OpenAI (if you have an API key)\n",
    "def summarize_with_openai(prompt):\n",
    "    try:\n",
    "        import openai\n",
    "    except ImportError:\n",
    "        raise RuntimeError(\"openai package not installed. pip install openai\")\n",
    "\n",
    "    openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    if not openai.api_key:\n",
    "        raise RuntimeError(\"Set OPENAI_API_KEY environment variable for OpenAI summarization\")\n",
    "\n",
    "    resp = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\":\"system\",\"content\":\"You are a concise assistant that returns exactly 3 sentences plus a confidence and sources line.\"},\n",
    "            {\"role\":\"user\",\"content\":prompt}\n",
    "        ],\n",
    "        temperature=0.0,\n",
    "        max_tokens=300,\n",
    "    )\n",
    "    return resp.choices[0].message.content.strip()\n",
    "\n",
    "def combine_page_summaries(page_summaries):\n",
    "    \"\"\"\n",
    "    page_summaries: list of dicts: { 'summary_text':..., 'ocr_conf':..., 'caption':... }\n",
    "    Produce a single consolidated 3-sentence summary and compute final confidence.\n",
    "    \"\"\"\n",
    "    combined_text = \"\\n\\n\".join([f\"Page {i+1} OCR:{p['ocr_text']}\\nCaption:{p['caption']}\" \n",
    "                                 for i,p in enumerate(page_summaries)])\n",
    "    prompt = \"Consolidate the following page-level context into a single concise 3-sentence professional summary using the same format (S1 scene, S2 textual content, S3 action/caveat). Then append a confidence (0-1) and data sources.\\n\\n\" + combined_text\n",
    "    consolidated = summarize_with_local_model(prompt)\n",
    "    # simple numeric confidence aggregation\n",
    "    avg_ocr_conf = sum(p['ocr_conf'] for p in page_summaries)/len(page_summaries) if page_summaries else 0.0\n",
    "    caption_score = sum(min(1, len(p['caption'])/50) for p in page_summaries)/len(page_summaries) if page_summaries else 0.0\n",
    "    final_conf = 0.7*avg_ocr_conf + 0.3*caption_score\n",
    "    return consolidated, float(final_conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "517ac89b-82a4-427e-8096-a7e8d4cbbd45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caption: a collage of photos showing a newspaper advertisement\n",
      "Summary:\n",
      " Describe the main scene (what's visible). - Sentence2 Describe the main scene (what's visible). - Sentence3 Describe the main scene (what's visible). - Sentence4 Describe the main scene (what's visible). - Sentence4 Describe the main scene (what's visible). - Sentence4 Describe the main scene (what's visible). - Sentence4 Describe the main scene (what's visible). - Sentence4 Describe the main scene (what's visible). - Sentence4 Describe the main scene (what's visible). - Sentence4 Describe the main scene (what's visible). - Sentence4 Describe the main scene (what's visible). - Sentence4 Describe the main scene (what's visible). - Sentence4 Describe the main scene (what's visible). - Sentence4 Describe the main scene (what's visible). - Sentence4 Describe the main scene (what's visible). - Sentence4\n"
     ]
    }
   ],
   "source": [
    "# Path to your image\n",
    "image_path = \"sample.png\"\n",
    "\n",
    "# Load image\n",
    "img = image_from_path_or_pil(image_path)\n",
    "\n",
    "# Run OCR\n",
    "ocr_text, ocr_conf = ocr_image_get_text_and_conf(img)\n",
    "\n",
    "# Run captioning\n",
    "caption = generate_caption(img)\n",
    "\n",
    "# Build prompt\n",
    "prompt = build_prompt(ocr_text, caption)\n",
    "\n",
    "# Summarize\n",
    "summary = summarize_with_local_model(prompt)\n",
    "\n",
    "# print(\"OCR text:\", ocr_text[:200], \"...\")\n",
    "print(\"Caption:\", caption)\n",
    "print(\"Summary:\\n\", summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bedc46-c930-4046-9ee3-cfc3f6c738c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your PDF\n",
    "pdf_path = \"document.pdf\"\n",
    "\n",
    "# Convert each page to images\n",
    "pages = pdf_to_images(pdf_path, dpi=200, poppler_path=r\"C:\\path\\to\\poppler\\bin\")  # on Windows\n",
    "# on Linux/Mac, just use: pdf_to_images(pdf_path)\n",
    "\n",
    "page_summaries = []\n",
    "for i, page_img in enumerate(pages):\n",
    "    ocr_text, ocr_conf = ocr_image_get_text_and_conf(page_img)\n",
    "    caption = generate_caption(page_img)\n",
    "    prompt = build_prompt(ocr_text, caption)\n",
    "    summary_text = summarize_with_local_model(prompt)\n",
    "    \n",
    "    page_summaries.append({\n",
    "        \"ocr_text\": ocr_text,\n",
    "        \"ocr_conf\": ocr_conf,\n",
    "        \"caption\": caption,\n",
    "        \"summary_text\": summary_text\n",
    "    })\n",
    "\n",
    "# Combine into one final summary\n",
    "final_summary, confidence = combine_page_summaries(page_summaries)\n",
    "\n",
    "print(\"Final summary:\\n\", final_summary)\n",
    "print(\"Confidence:\", confidence)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
